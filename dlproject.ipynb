{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# General E(2)-Equivariant Steerable CNNs  -  A concrete example\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import time\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import cv2\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision.transforms import RandomRotation, Pad, Resize, ToTensor, Compose\n",
    "from torchsummary import summary\n",
    "\n",
    "from e2cnn import gspaces\n",
    "from e2cnn import nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we build a **Steerable CNN** and try it MNIST.\n",
    "\n",
    "Let's also use a group a bit larger: we now build a model equivariant to $8$ rotations.\n",
    "We indicate the group of $N$ discrete rotations as $C_N$, i.e. the **cyclic group** of order $N$.\n",
    "In this case, we will use $C_8$.\n",
    "\n",
    "Because the inputs are still gray-scale images, the input type of the model is again a *scalar field*.\n",
    "\n",
    "However, internally we use *regular fields*: this is equivalent to a *group-equivariant convolutional neural network*.\n",
    "\n",
    "Finally, we build *invariant* features for the final classification task by pooling over the group using *Group Pooling*.\n",
    "\n",
    "The final classification is performed by a two fully connected layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The model\n",
    "\n",
    "Here is the definition of our model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class C8SteerableCNN(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, n_classes=10, cyclic_group=8):\n",
    "        self.cyclic_group=cyclic_group\n",
    "        \n",
    "        super(C8SteerableCNN, self).__init__()\n",
    "        \n",
    "        # the model is equivariant under rotations by 45 degrees, modelled by C8\n",
    "        self.r2_act = gspaces.Rot2dOnR2(N=self.cyclic_group)\n",
    "        #print(\"self.r2_act\", self.r2_act)\n",
    "        \n",
    "        # the input image is a scalar field, corresponding to the trivial representation\n",
    "        in_type = nn.FieldType(self.r2_act, 3*[self.r2_act.trivial_repr])\n",
    "        #print(\"in_type\", in_type)\n",
    "        \n",
    "        # we store the input type for wrapping the images into a geometric tensor during the forward pass\n",
    "        self.input_type = in_type\n",
    "        \n",
    "        # convolution 1\n",
    "        # first specify the output type of the convolutional layer\n",
    "        # we choose 24 feature fields, each transforming under the regular representation of C8\n",
    "        out_type = nn.FieldType(self.r2_act, 24*[self.r2_act.regular_repr])\n",
    "        #print(\"out_type\", out_type)\n",
    "        self.block1 = nn.SequentialModule(\n",
    "            nn.MaskModule(in_type, 80, margin=1),\n",
    "            nn.R2Conv(in_type, out_type, kernel_size=7, padding=1, bias=False),\n",
    "            nn.InnerBatchNorm(out_type),\n",
    "            nn.ReLU(out_type, inplace=True)\n",
    "        )\n",
    "        print('block1', self.block1.out_type.size)\n",
    "        \n",
    "        # convolution 2\n",
    "        # the old output type is the input type to the next layer\n",
    "        in_type = self.block1.out_type\n",
    "        # the output type of the second convolution layer are 48 regular feature fields of C8\n",
    "        out_type = nn.FieldType(self.r2_act, 48*[self.r2_act.regular_repr])\n",
    "        self.block2 = nn.SequentialModule(\n",
    "            nn.R2Conv(in_type, out_type, kernel_size=5, padding=2, bias=False),\n",
    "            nn.InnerBatchNorm(out_type),\n",
    "            nn.ReLU(out_type, inplace=True)\n",
    "        )\n",
    "        print('block2', self.block2.out_type.size)\n",
    "        self.pool1 = nn.SequentialModule(\n",
    "            nn.PointwiseAvgPoolAntialiased(out_type, sigma=0.66, stride=2)\n",
    "        )\n",
    "        print('pool1', self.pool1.out_type.size)\n",
    "        \n",
    "        # convolution 3\n",
    "        # the old output type is the input type to the next layer\n",
    "        in_type = self.block2.out_type\n",
    "        # the output type of the third convolution layer are 48 regular feature fields of C8\n",
    "        out_type = nn.FieldType(self.r2_act, 48*[self.r2_act.regular_repr])\n",
    "        self.block3 = nn.SequentialModule(\n",
    "            nn.R2Conv(in_type, out_type, kernel_size=5, padding=2, bias=False),\n",
    "            nn.InnerBatchNorm(out_type),\n",
    "            nn.ReLU(out_type, inplace=True)\n",
    "        )\n",
    "        print('block3', self.block3.out_type.size)\n",
    "        \n",
    "        # convolution 4\n",
    "        # the old output type is the input type to the next layer\n",
    "        in_type = self.block3.out_type\n",
    "        # the output type of the fourth convolution layer are 96 regular feature fields of C8\n",
    "        out_type = nn.FieldType(self.r2_act, 96*[self.r2_act.regular_repr])\n",
    "        self.block4 = nn.SequentialModule(\n",
    "            nn.R2Conv(in_type, out_type, kernel_size=5, padding=2, bias=False),\n",
    "            nn.InnerBatchNorm(out_type),\n",
    "            nn.ReLU(out_type, inplace=True)\n",
    "        )\n",
    "        print('block4', self.block4.out_type.size)\n",
    "        self.pool2 = nn.SequentialModule(\n",
    "            nn.PointwiseAvgPoolAntialiased(out_type, sigma=0.66, stride=2)\n",
    "        )\n",
    "        print('pool2', self.pool2.out_type.size)\n",
    "        \n",
    "        # convolution 5\n",
    "        # the old output type is the input type to the next layer\n",
    "        in_type = self.block4.out_type\n",
    "        # the output type of the fifth convolution layer are 96 regular feature fields of C8\n",
    "        out_type = nn.FieldType(self.r2_act, 96*[self.r2_act.regular_repr])\n",
    "        self.block5 = nn.SequentialModule(\n",
    "            nn.R2Conv(in_type, out_type, kernel_size=5, padding=2, bias=False),\n",
    "            nn.InnerBatchNorm(out_type),\n",
    "            nn.ReLU(out_type, inplace=True)\n",
    "        )\n",
    "        print('block5', self.block5.out_type.size)\n",
    "        \n",
    "        # convolution 6\n",
    "        # the old output type is the input type to the next layer\n",
    "        in_type = self.block5.out_type\n",
    "        # the output type of the sixth convolution layer are 64 regular feature fields of C8\n",
    "        out_type = nn.FieldType(self.r2_act, 64*[self.r2_act.regular_repr])\n",
    "        self.block6 = nn.SequentialModule(\n",
    "            nn.R2Conv(in_type, out_type, kernel_size=5, padding=1, bias=False),\n",
    "            nn.InnerBatchNorm(out_type),\n",
    "            nn.ReLU(out_type, inplace=True)\n",
    "        )\n",
    "        print('block6', self.block6.out_type.size)\n",
    "        self.pool3 = nn.PointwiseAvgPoolAntialiased(out_type, sigma=0.66, stride=1, padding=0)\n",
    "        print('pool3', self.pool3.out_type.size)\n",
    "        \n",
    "        self.gpool = nn.GroupPooling(out_type) # pool3.out_type\n",
    "        \n",
    "        # number of output channels\n",
    "        c = self.gpool.out_type.size\n",
    "        print('gpool', c)\n",
    "        \n",
    "        # Fully Connected\n",
    "        self.fully_net = torch.nn.Sequential(\n",
    "            torch.nn.Linear(c*13*13, 64),\n",
    "            torch.nn.BatchNorm1d(64),\n",
    "            torch.nn.ELU(inplace=True),\n",
    "            torch.nn.Linear(64, n_classes),\n",
    "        )\n",
    "    \n",
    "    def forward(self, input: torch.Tensor):\n",
    "        # wrap the input tensor in a GeometricTensor\n",
    "        # (associate it with the input type)\n",
    "        #print(\"input.shape\", input.shape)\n",
    "        x = nn.GeometricTensor(input, self.input_type)\n",
    "        \n",
    "        # apply each equivariant block\n",
    "        \n",
    "        # Each layer has an input and an output type\n",
    "        # A layer takes a GeometricTensor in input.\n",
    "        # This tensor needs to be associated with the same representation of the layer's input type\n",
    "        #\n",
    "        # The Layer outputs a new GeometricTensor, associated with the layer's output type.\n",
    "        # As a result, consecutive layers need to have matching input/output types\n",
    "        x = self.block1(x)\n",
    "        x = self.block2(x)\n",
    "        x = self.pool1(x)\n",
    "        \n",
    "        x = self.block3(x)\n",
    "        x = self.block4(x)\n",
    "        x = self.pool2(x)\n",
    "        \n",
    "        x = self.block5(x)\n",
    "        x = self.block6(x)\n",
    "        \n",
    "        # pool over the spatial dimensions\n",
    "        x = self.pool3(x)\n",
    "        #print(\"x.shape1\", x.shape)\n",
    "        \n",
    "        # pool over the group\n",
    "        x = self.gpool(x)\n",
    "        #print(\"x.shape2\", x.shape)\n",
    "\n",
    "        # unwrap the output GeometricTensor\n",
    "        # (take the Pytorch tensor and discard the associated representation)\n",
    "        x = x.tensor\n",
    "        #print(\"x.shape3\", x.shape)\n",
    "        \n",
    "        # classify with the final fully connected layers)\n",
    "        x = self.fully_net(x.reshape(x.shape[0], -1))\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not rotationally-equivariant architecture, mimics above as closely as possible\n",
    "class NonRECNN(torch.nn.Module):\n",
    "    def __init__(self, n_classes=10):\n",
    "        super().__init__()\n",
    "        \n",
    "        # convolution 1\n",
    "        self.block1 = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(in_channels=3, out_channels=24, kernel_size=7, stride=1, padding=1, bias=False),\n",
    "            torch.nn.BatchNorm2d(num_features=24),\n",
    "            torch.nn.ReLU(inplace=True)\n",
    "        )\n",
    "        \n",
    "        # convolution 2\n",
    "        self.block2 = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(in_channels=24, out_channels=48, kernel_size=5, stride=1, padding=2, bias=False),\n",
    "            torch.nn.BatchNorm2d(num_features=48),\n",
    "            torch.nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.pool1 = torch.nn.AvgPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        # convolution 3\n",
    "        self.block3 = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(in_channels=48, out_channels=48, kernel_size=5, stride=1, padding=2, bias=False),\n",
    "            torch.nn.BatchNorm2d(num_features=48),\n",
    "            torch.nn.ReLU(inplace=True)\n",
    "        )\n",
    "        \n",
    "        # convolution 4\n",
    "        self.block4 = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(in_channels=48, out_channels=96, kernel_size=5, stride=1, padding=2, bias=False),\n",
    "            torch.nn.BatchNorm2d(num_features=96),\n",
    "            torch.nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.pool2 = torch.nn.AvgPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        # convolution 5\n",
    "        self.block5 = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(in_channels=96, out_channels=96, kernel_size=5, stride=1, padding=2, bias=False),\n",
    "            torch.nn.BatchNorm2d(num_features=96),\n",
    "            torch.nn.ReLU(inplace=True)\n",
    "        )\n",
    "        \n",
    "        # convolution 6\n",
    "        self.block6 = torch.nn.Sequential(\n",
    "            # NOTE 1: changed padding=1 to padding=0 in this layer to help match input size of fc layer\n",
    "            torch.nn.Conv2d(in_channels=96, out_channels=64, kernel_size=5, stride=1, padding=0, bias=False),\n",
    "            torch.nn.BatchNorm2d(num_features=64),\n",
    "            torch.nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.pool3 = torch.nn.AvgPool2d(kernel_size=2, stride=1, padding=0)\n",
    "        # NOTE 2: added another avgpool2d to match input size of fc layer\n",
    "        self.pool4 = torch.nn.AvgPool2d(kernel_size=2, stride=1, padding=0)\n",
    "#        self.pool5 = torch.nn.AvgPool2d(kernel_size=2, stride=1, padding=0)\n",
    "#        self.pool6 = torch.nn.AvgPool2d(kernel_size=2, stride=1, padding=0)\n",
    "\n",
    "        # Fully Connected\n",
    "        self.fully_net = torch.nn.Sequential(\n",
    "            torch.nn.Linear(64*13*13, 64),\n",
    "            torch.nn.BatchNorm1d(num_features=64),\n",
    "            torch.nn.ELU(inplace=True),\n",
    "            torch.nn.Linear(64, n_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.block1(x)\n",
    "        x = self.block2(x)\n",
    "        x = self.pool1(x)\n",
    "        \n",
    "        x = self.block3(x)\n",
    "        x = self.block4(x)\n",
    "        x = self.pool2(x)\n",
    "        \n",
    "        x = self.block5(x)\n",
    "        x = self.block6(x)\n",
    "        x = self.pool3(x)\n",
    "        x = self.pool4(x)\n",
    "#        x = self.pool5(x)\n",
    "#        x = self.pool6(x)\n",
    "        \n",
    "        # flatten all dimensions except batch\n",
    "        x = torch.flatten(x, 1)\n",
    "        \n",
    "        # classify with the final fully connected layers)\n",
    "        x = self.fully_net(x.reshape(x.shape[0], -1))\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "#device = 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "block1 192\n",
      "block2 384\n",
      "pool1 384\n",
      "block3 384\n",
      "block4 768\n",
      "pool2 768\n",
      "block5 768\n",
      "block6 512\n",
      "pool3 512\n",
      "gpool 64\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "        MaskModule-1            [-1, 3, 80, 80]               0\n",
      "SingleBlockBasisExpansion-2             [-1, 8, 1, 49]               0\n",
      "BlocksBasisExpansion-3                [-1, 3, 49]               0\n",
      "            R2Conv-4          [-1, 192, 76, 76]               0\n",
      "       BatchNorm3d-5        [-1, 24, 8, 76, 76]              48\n",
      "    InnerBatchNorm-6          [-1, 192, 76, 76]               0\n",
      "              ReLU-7          [-1, 192, 76, 76]               0\n",
      "  SequentialModule-8          [-1, 192, 76, 76]               0\n",
      "SingleBlockBasisExpansion-9             [-1, 8, 8, 25]               0\n",
      "SingleBlockBasisExpansion-10             [-1, 8, 8, 25]               0\n",
      "SingleBlockBasisExpansion-11             [-1, 8, 8, 25]               0\n",
      "SingleBlockBasisExpansion-12             [-1, 8, 8, 25]               0\n",
      "SingleBlockBasisExpansion-13             [-1, 8, 8, 25]               0\n",
      "BlocksBasisExpansion-14              [-1, 192, 25]               0\n",
      "           R2Conv-15          [-1, 384, 76, 76]               0\n",
      "      BatchNorm3d-16        [-1, 48, 8, 76, 76]              96\n",
      "   InnerBatchNorm-17          [-1, 384, 76, 76]               0\n",
      "             ReLU-18          [-1, 384, 76, 76]               0\n",
      " SequentialModule-19          [-1, 384, 76, 76]               0\n",
      "PointwiseAvgPoolAntialiased-20          [-1, 384, 38, 38]               0\n",
      " SequentialModule-21          [-1, 384, 38, 38]               0\n",
      "SingleBlockBasisExpansion-22             [-1, 8, 8, 25]               0\n",
      "SingleBlockBasisExpansion-23             [-1, 8, 8, 25]               0\n",
      "SingleBlockBasisExpansion-24             [-1, 8, 8, 25]               0\n",
      "SingleBlockBasisExpansion-25             [-1, 8, 8, 25]               0\n",
      "SingleBlockBasisExpansion-26             [-1, 8, 8, 25]               0\n",
      "BlocksBasisExpansion-27              [-1, 384, 25]               0\n",
      "           R2Conv-28          [-1, 384, 38, 38]               0\n",
      "      BatchNorm3d-29        [-1, 48, 8, 38, 38]              96\n",
      "   InnerBatchNorm-30          [-1, 384, 38, 38]               0\n",
      "             ReLU-31          [-1, 384, 38, 38]               0\n",
      " SequentialModule-32          [-1, 384, 38, 38]               0\n",
      "SingleBlockBasisExpansion-33             [-1, 8, 8, 25]               0\n",
      "SingleBlockBasisExpansion-34             [-1, 8, 8, 25]               0\n",
      "SingleBlockBasisExpansion-35             [-1, 8, 8, 25]               0\n",
      "SingleBlockBasisExpansion-36             [-1, 8, 8, 25]               0\n",
      "SingleBlockBasisExpansion-37             [-1, 8, 8, 25]               0\n",
      "BlocksBasisExpansion-38              [-1, 384, 25]               0\n",
      "           R2Conv-39          [-1, 768, 38, 38]               0\n",
      "      BatchNorm3d-40        [-1, 96, 8, 38, 38]             192\n",
      "   InnerBatchNorm-41          [-1, 768, 38, 38]               0\n",
      "             ReLU-42          [-1, 768, 38, 38]               0\n",
      " SequentialModule-43          [-1, 768, 38, 38]               0\n",
      "PointwiseAvgPoolAntialiased-44          [-1, 768, 19, 19]               0\n",
      " SequentialModule-45          [-1, 768, 19, 19]               0\n",
      "SingleBlockBasisExpansion-46             [-1, 8, 8, 25]               0\n",
      "SingleBlockBasisExpansion-47             [-1, 8, 8, 25]               0\n",
      "SingleBlockBasisExpansion-48             [-1, 8, 8, 25]               0\n",
      "SingleBlockBasisExpansion-49             [-1, 8, 8, 25]               0\n",
      "SingleBlockBasisExpansion-50             [-1, 8, 8, 25]               0\n",
      "BlocksBasisExpansion-51              [-1, 768, 25]               0\n",
      "           R2Conv-52          [-1, 768, 19, 19]               0\n",
      "      BatchNorm3d-53        [-1, 96, 8, 19, 19]             192\n",
      "   InnerBatchNorm-54          [-1, 768, 19, 19]               0\n",
      "             ReLU-55          [-1, 768, 19, 19]               0\n",
      " SequentialModule-56          [-1, 768, 19, 19]               0\n",
      "SingleBlockBasisExpansion-57             [-1, 8, 8, 25]               0\n",
      "SingleBlockBasisExpansion-58             [-1, 8, 8, 25]               0\n",
      "SingleBlockBasisExpansion-59             [-1, 8, 8, 25]               0\n",
      "SingleBlockBasisExpansion-60             [-1, 8, 8, 25]               0\n",
      "SingleBlockBasisExpansion-61             [-1, 8, 8, 25]               0\n",
      "BlocksBasisExpansion-62              [-1, 768, 25]               0\n",
      "           R2Conv-63          [-1, 512, 17, 17]               0\n",
      "      BatchNorm3d-64        [-1, 64, 8, 17, 17]             128\n",
      "   InnerBatchNorm-65          [-1, 512, 17, 17]               0\n",
      "             ReLU-66          [-1, 512, 17, 17]               0\n",
      " SequentialModule-67          [-1, 512, 17, 17]               0\n",
      "PointwiseAvgPoolAntialiased-68          [-1, 512, 13, 13]               0\n",
      "     GroupPooling-69           [-1, 64, 13, 13]               0\n",
      "           Linear-70                   [-1, 64]         692,288\n",
      "      BatchNorm1d-71                   [-1, 64]             128\n",
      "              ELU-72                   [-1, 64]               0\n",
      "           Linear-73                   [-1, 15]             975\n",
      "================================================================\n",
      "Total params: 694,143\n",
      "Trainable params: 694,143\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.07\n",
      "Forward/backward pass size (MB): 220.96\n",
      "Params size (MB): 2.65\n",
      "Estimated Total Size (MB): 223.68\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "cyclic_group = 8\n",
    "n_classes = 15\n",
    "\n",
    "model = C8SteerableCNN(n_classes=n_classes, cyclic_group=cyclic_group).to(device)\n",
    "\n",
    "summary(model, input_size=(3, 80, 80))\n",
    "\n",
    "# cyclic_group = 1\n",
    "# n_classes = 15\n",
    "\n",
    "# model = NonRECNN(n_classes=n_classes).to(device)\n",
    "\n",
    "# summary(model, input_size=(3, 80, 80))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "block1 192\n",
      "block2 384\n",
      "pool1 384\n",
      "block3 384\n",
      "block4 768\n",
      "pool2 768\n",
      "block5 768\n",
      "block6 512\n",
      "pool3 512\n",
      "gpool 64\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "        MaskModule-1            [-1, 3, 80, 80]               0\n",
      "SingleBlockBasisExpansion-2             [-1, 8, 1, 49]               0\n",
      "BlocksBasisExpansion-3                [-1, 3, 49]               0\n",
      "            R2Conv-4          [-1, 192, 76, 76]               0\n",
      "       BatchNorm3d-5        [-1, 24, 8, 76, 76]              48\n",
      "    InnerBatchNorm-6          [-1, 192, 76, 76]               0\n",
      "              ReLU-7          [-1, 192, 76, 76]               0\n",
      "  SequentialModule-8          [-1, 192, 76, 76]               0\n",
      "SingleBlockBasisExpansion-9             [-1, 8, 8, 25]               0\n",
      "SingleBlockBasisExpansion-10             [-1, 8, 8, 25]               0\n",
      "SingleBlockBasisExpansion-11             [-1, 8, 8, 25]               0\n",
      "SingleBlockBasisExpansion-12             [-1, 8, 8, 25]               0\n",
      "SingleBlockBasisExpansion-13             [-1, 8, 8, 25]               0\n",
      "BlocksBasisExpansion-14              [-1, 192, 25]               0\n",
      "           R2Conv-15          [-1, 384, 76, 76]               0\n",
      "      BatchNorm3d-16        [-1, 48, 8, 76, 76]              96\n",
      "   InnerBatchNorm-17          [-1, 384, 76, 76]               0\n",
      "             ReLU-18          [-1, 384, 76, 76]               0\n",
      " SequentialModule-19          [-1, 384, 76, 76]               0\n",
      "PointwiseAvgPoolAntialiased-20          [-1, 384, 38, 38]               0\n",
      " SequentialModule-21          [-1, 384, 38, 38]               0\n",
      "SingleBlockBasisExpansion-22             [-1, 8, 8, 25]               0\n",
      "SingleBlockBasisExpansion-23             [-1, 8, 8, 25]               0\n",
      "SingleBlockBasisExpansion-24             [-1, 8, 8, 25]               0\n",
      "SingleBlockBasisExpansion-25             [-1, 8, 8, 25]               0\n",
      "SingleBlockBasisExpansion-26             [-1, 8, 8, 25]               0\n",
      "BlocksBasisExpansion-27              [-1, 384, 25]               0\n",
      "           R2Conv-28          [-1, 384, 38, 38]               0\n",
      "      BatchNorm3d-29        [-1, 48, 8, 38, 38]              96\n",
      "   InnerBatchNorm-30          [-1, 384, 38, 38]               0\n",
      "             ReLU-31          [-1, 384, 38, 38]               0\n",
      " SequentialModule-32          [-1, 384, 38, 38]               0\n",
      "SingleBlockBasisExpansion-33             [-1, 8, 8, 25]               0\n",
      "SingleBlockBasisExpansion-34             [-1, 8, 8, 25]               0\n",
      "SingleBlockBasisExpansion-35             [-1, 8, 8, 25]               0\n",
      "SingleBlockBasisExpansion-36             [-1, 8, 8, 25]               0\n",
      "SingleBlockBasisExpansion-37             [-1, 8, 8, 25]               0\n",
      "BlocksBasisExpansion-38              [-1, 384, 25]               0\n",
      "           R2Conv-39          [-1, 768, 38, 38]               0\n",
      "      BatchNorm3d-40        [-1, 96, 8, 38, 38]             192\n",
      "   InnerBatchNorm-41          [-1, 768, 38, 38]               0\n",
      "             ReLU-42          [-1, 768, 38, 38]               0\n",
      " SequentialModule-43          [-1, 768, 38, 38]               0\n",
      "PointwiseAvgPoolAntialiased-44          [-1, 768, 19, 19]               0\n",
      " SequentialModule-45          [-1, 768, 19, 19]               0\n",
      "SingleBlockBasisExpansion-46             [-1, 8, 8, 25]               0\n",
      "SingleBlockBasisExpansion-47             [-1, 8, 8, 25]               0\n",
      "SingleBlockBasisExpansion-48             [-1, 8, 8, 25]               0\n",
      "SingleBlockBasisExpansion-49             [-1, 8, 8, 25]               0\n",
      "SingleBlockBasisExpansion-50             [-1, 8, 8, 25]               0\n",
      "BlocksBasisExpansion-51              [-1, 768, 25]               0\n",
      "           R2Conv-52          [-1, 768, 19, 19]               0\n",
      "      BatchNorm3d-53        [-1, 96, 8, 19, 19]             192\n",
      "   InnerBatchNorm-54          [-1, 768, 19, 19]               0\n",
      "             ReLU-55          [-1, 768, 19, 19]               0\n",
      " SequentialModule-56          [-1, 768, 19, 19]               0\n",
      "SingleBlockBasisExpansion-57             [-1, 8, 8, 25]               0\n",
      "SingleBlockBasisExpansion-58             [-1, 8, 8, 25]               0\n",
      "SingleBlockBasisExpansion-59             [-1, 8, 8, 25]               0\n",
      "SingleBlockBasisExpansion-60             [-1, 8, 8, 25]               0\n",
      "SingleBlockBasisExpansion-61             [-1, 8, 8, 25]               0\n",
      "BlocksBasisExpansion-62              [-1, 768, 25]               0\n",
      "           R2Conv-63          [-1, 512, 17, 17]               0\n",
      "      BatchNorm3d-64        [-1, 64, 8, 17, 17]             128\n",
      "   InnerBatchNorm-65          [-1, 512, 17, 17]               0\n",
      "             ReLU-66          [-1, 512, 17, 17]               0\n",
      " SequentialModule-67          [-1, 512, 17, 17]               0\n",
      "PointwiseAvgPoolAntialiased-68          [-1, 512, 13, 13]               0\n",
      "     GroupPooling-69           [-1, 64, 13, 13]               0\n",
      "           Linear-70                   [-1, 64]         692,288\n",
      "      BatchNorm1d-71                   [-1, 64]             128\n",
      "              ELU-72                   [-1, 64]               0\n",
      "           Linear-73                   [-1, 15]             975\n",
      "================================================================\n",
      "Total params: 694,143\n",
      "Trainable params: 694,143\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.07\n",
      "Forward/backward pass size (MB): 220.96\n",
      "Params size (MB): 2.65\n",
      "Estimated Total Size (MB): 223.68\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "cyclic_group = 8\n",
    "n_classes = 15\n",
    "\n",
    "model1 = C8SteerableCNN(n_classes=n_classes, cyclic_group=cyclic_group).to(device)\n",
    "summary(model1, input_size=(3, 80, 80))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 24, 76, 76]           3,528\n",
      "       BatchNorm2d-2           [-1, 24, 76, 76]              48\n",
      "              ReLU-3           [-1, 24, 76, 76]               0\n",
      "            Conv2d-4           [-1, 48, 76, 76]          28,800\n",
      "       BatchNorm2d-5           [-1, 48, 76, 76]              96\n",
      "              ReLU-6           [-1, 48, 76, 76]               0\n",
      "         AvgPool2d-7           [-1, 48, 38, 38]               0\n",
      "            Conv2d-8           [-1, 48, 38, 38]          57,600\n",
      "       BatchNorm2d-9           [-1, 48, 38, 38]              96\n",
      "             ReLU-10           [-1, 48, 38, 38]               0\n",
      "           Conv2d-11           [-1, 96, 38, 38]         115,200\n",
      "      BatchNorm2d-12           [-1, 96, 38, 38]             192\n",
      "             ReLU-13           [-1, 96, 38, 38]               0\n",
      "        AvgPool2d-14           [-1, 96, 19, 19]               0\n",
      "           Conv2d-15           [-1, 96, 19, 19]         230,400\n",
      "      BatchNorm2d-16           [-1, 96, 19, 19]             192\n",
      "             ReLU-17           [-1, 96, 19, 19]               0\n",
      "           Conv2d-18           [-1, 64, 15, 15]         153,600\n",
      "      BatchNorm2d-19           [-1, 64, 15, 15]             128\n",
      "             ReLU-20           [-1, 64, 15, 15]               0\n",
      "        AvgPool2d-21           [-1, 64, 14, 14]               0\n",
      "        AvgPool2d-22           [-1, 64, 13, 13]               0\n",
      "           Linear-23                   [-1, 64]         692,288\n",
      "      BatchNorm1d-24                   [-1, 64]             128\n",
      "              ELU-25                   [-1, 64]               0\n",
      "           Linear-26                   [-1, 15]             975\n",
      "================================================================\n",
      "Total params: 1,283,271\n",
      "Trainable params: 1,283,271\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.07\n",
      "Forward/backward pass size (MB): 16.37\n",
      "Params size (MB): 4.90\n",
      "Estimated Total Size (MB): 21.34\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model2 = NonRECNN(n_classes=n_classes).to(device)\n",
    "summary(model2, input_size=(3, 80, 80))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is now randomly initialized. \n",
    "Therefore, we do not expect it to produce the right class probabilities.\n",
    "\n",
    "However, the model should still produce the same output for rotated versions of the same image.\n",
    "This is true for rotations by multiples of $\\frac{\\pi}{2}$, but is only approximate for rotations by $\\frac{\\pi}{4}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try the model on *rotated* MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # download the dataset\n",
    "# !wget -nc http://www.iro.umontreal.ca/~lisa/icml2007data/mnist_rotation_new.zip\n",
    "# # uncompress the zip file\n",
    "# !unzip -n mnist_rotation_new.zip -d mnist_rotation_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import requests\n",
    "# url = 'http://www.iro.umontreal.ca/~lisa/icml2007data/mnist_rotation_new.zip'\n",
    "# doc = requests.get(url)\n",
    "# with open('mnistrot.zip', 'wb') as f:\n",
    "#     f.write(doc.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DOTARotDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, mode, transform=None, max_num_examples=0):\n",
    "        assert mode in ['train', 'test']\n",
    "        \n",
    "        basedir = 'C:/Users/Admin/Desktop/data/DOTAv1.0/'\n",
    "        \n",
    "        if mode == \"train\":\n",
    "            file = basedir+\"chips_train/\"\n",
    "        else:\n",
    "            file = basedir+\"chips_val/\"\n",
    "        \n",
    "        self.transform = transform\n",
    "        self.max_num_examples = max_num_examples\n",
    "        self.images = []\n",
    "        self.labels = []\n",
    "        new_image_width = 80\n",
    "        new_image_height = 80\n",
    "        color = (0,0,0)\n",
    "        self.classdict = {}\n",
    "        self.classval = 0\n",
    "\n",
    "        #data = np.loadtxt(file, delimiter=' ')\n",
    "        data = []\n",
    "        \n",
    "        for root, dirs, filenames in os.walk(file, topdown=False):\n",
    "            pass\n",
    "        for d in dirs:\n",
    "            for root, dirs, filenames in os.walk(file+d, topdown=False):\n",
    "                pass\n",
    "            #print(d, len(filenames))\n",
    "            for f in filenames:\n",
    "                imgstr = file+d+\"/\"+f\n",
    "                #img = Image.open(imgstr)\n",
    "                #arr = np.asarray(img)\n",
    "                img = cv2.imread(imgstr)\n",
    "                old_image_height, old_image_width, channels = img.shape\n",
    "                #print('old', old_image_height, old_image_width)\n",
    "                if img.shape[0] < img.shape[1]:\n",
    "                    result1 = np.full((img.shape[1],img.shape[1], channels), color, dtype=np.uint8)\n",
    "                    #print('shape', result1.shape)\n",
    "                    # compute center offset\n",
    "                    #x_center = np.abs(new_image_width - old_image_width) // 2\n",
    "                    y_center = np.abs(img.shape[1] - old_image_height) // 2\n",
    "                    #print('y_center', y_center)\n",
    "                    # copy img image into center of result image\n",
    "                    result1[y_center:y_center+old_image_height, :] = img\n",
    "                elif img.shape[0] > img.shape[1]:\n",
    "                    result1 = np.full((img.shape[0],img.shape[0], channels), color, dtype=np.uint8)\n",
    "                    #print('shape', result1.shape)\n",
    "                    # compute center offset\n",
    "                    x_center = np.abs(img.shape[0] - old_image_width) // 2\n",
    "                    #y_center = np.abs(new_image_height - old_image_height) // 2\n",
    "                    #print('x_center', x_center)\n",
    "                    # copy img image into center of result image\n",
    "                    result1[:, x_center:x_center+old_image_width] = img\n",
    "                else:\n",
    "                    result1 = img[:,:,:]\n",
    "                # check if we need to resize\n",
    "                if not (result1.shape[0] == 80 and result1.shape[1] == 80):\n",
    "                    #print('result1.shape1', result1.shape)\n",
    "                    result1 = cv2.resize(result1, dsize=(80, 80), interpolation=cv2.INTER_CUBIC)\n",
    "                    #print('result1.shape2', result1.shape)\n",
    "                res2 = result1.reshape(-1, 80, 80).astype(np.float32) # = arr[:, :-1].reshape(-1, 80, 80)\n",
    "                #print('res2.shape', res2.shape)\n",
    "                \n",
    "                # ToTensor screws up the order, so we have to undo it:\n",
    "                # https://discuss.pytorch.org/t/torchvision-totensor-dont-change-channel-order/82038/2\n",
    "                #res2 = res2.permute((1, 2, 0)).contiguous()\n",
    "                \n",
    "                # convert back to PIL Image object for pytorch transforms (e.g. RandomRotation) to work\n",
    "                #image = Image.fromarray(image)\n",
    "                \n",
    "                self.images.append(res2)\n",
    "        \n",
    "                # labels\n",
    "                if self.classdict.get(d, -1) >= 0:\n",
    "                    self.labels.append(self.classdict[d])\n",
    "                else: # it's not in self.classdict yet\n",
    "                    self.classdict[d] = self.classval\n",
    "                    self.classval += 1\n",
    "        \n",
    "        if self.max_num_examples > 0:\n",
    "            #z1 = list(zip(self.images, self.labels))\n",
    "            classdict = {}\n",
    "            for i in range(len(self.labels)):\n",
    "                if classdict.get(self.labels[i], False):\n",
    "                    classdict[self.labels[i]].append(self.images[i])\n",
    "                else:\n",
    "                    classdict[self.labels[i]] = [self.images[i]]\n",
    "            self.images = []\n",
    "            self.labels = []\n",
    "            for i in range(self.classval):\n",
    "                if len(classdict[i]) > self.max_num_examples:\n",
    "                    temp = random.sample(classdict[i], self.max_num_examples)\n",
    "                    for t in temp:\n",
    "                        self.images.append(t)\n",
    "                        self.labels.append(i)\n",
    "                else:\n",
    "                    for t in classdict[i]:\n",
    "                        self.images.append(t)\n",
    "                        self.labels.append(i)\n",
    "\n",
    "        self.num_samples = len(self.labels)\n",
    "        print(\"self.num_samples\", self.num_samples)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        image, label = self.images[index], self.labels[index]\n",
    "        # image is a numpy ndarray instead of PIL Image object\n",
    "        # NOTE: certain pytorch functions (aka RandomRotate) require PIL Image objects\n",
    "        # ToTensor screws up the shape/channel order, so we have to undo it:\n",
    "        # https://discuss.pytorch.org/t/torchvision-totensor-dont-change-channel-order/82038/2\n",
    "        #image = image.permute((1, 2, 0)).contiguous()\n",
    "        #image = Image.fromarray(image)\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "# images are padded to have shape 29x29.\n",
    "# this allows to use odd-size filters with stride 2 when downsampling a feature map in the model\n",
    "#pad = Pad((0, 0, 1, 1), fill=0)\n",
    "\n",
    "# to reduce interpolation artifacts (e.g. when testing the model on rotated images),\n",
    "# we upsample an image by a factor of 3, rotate it and finally downsample it again\n",
    "#resize1 = Resize(80*3)\n",
    "#resize2 = Resize(80)\n",
    "\n",
    "#totensor = ToTensor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the test set\n",
    "#raw_mnist_test = DOTARotDataset(mode='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve the first image from the test set\n",
    "#x, y = next(iter(raw_mnist_test))\n",
    "#\n",
    "#print(x.shape)\n",
    "#print(raw_mnist_test[3530])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model: torch.nn.Module, x: Image):\n",
    "    # evaluate the `model` on 8 rotated versions of the input image `x`\n",
    "    model.eval()\n",
    "    totensor = ToTensor()\n",
    "    \n",
    "    wrmup = model(torch.randn(1, 3, 80, 80).to(device))\n",
    "    del wrmup\n",
    "    \n",
    "    #x = resize1(pad(x))\n",
    "    \n",
    "    print()\n",
    "    print('##########################################################################################')\n",
    "    header = 'angle |  ' + '  '.join([\"{:6d}\".format(d) for d in range(15)])\n",
    "    print(header)\n",
    "    with torch.no_grad():\n",
    "        for r in range(8):\n",
    "            #print(np.min(x), np.max(x), x.shape)\n",
    "            intimg = x.astype(np.uint8)\n",
    "            #print(type(intimg))\n",
    "            #print(np.min(intimg), np.max(intimg), intimg.shape)\n",
    "            # go from 3,80,80 -> 80,80,3\n",
    "            #intimg2 = intimg.permute((1, 2, 0)).contiguous() # can't permute numpy arrays\n",
    "            intimg2 = intimg.transpose(1, 2, 0)\n",
    "            #print(np.min(intimg2), np.max(intimg2), intimg2.shape)\n",
    "            img = Image.fromarray(intimg2)\n",
    "            #print(np.min(img), np.max(img))\n",
    "            rotimg = img.rotate(r*45., Image.BILINEAR)\n",
    "            #print(rotimg.shape)\n",
    "            x_transformed = totensor(rotimg).reshape(-1, 3, 80, 80)\n",
    "            x_transformed = x_transformed.to(device)\n",
    "\n",
    "            y = model(x_transformed)\n",
    "            y = y.to('cpu').numpy().squeeze()\n",
    "            \n",
    "            angle = r * 45\n",
    "            print(\"{:3d}:{}\".format(angle, y))\n",
    "    print('##########################################################################################')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the model\n",
    "#test_model(model, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output of the model is already almost invariant.\n",
    "However, we still observe small fluctuations in the outputs.\n",
    "\n",
    "This is because the model contains some operations which might break equivariance.\n",
    "For instance, every convolution includes a padding of $2$ pixels per side. This is adds information about the actual orientation of the grid where the image/feature map is sampled because the padding is not rotated with the image. \n",
    "\n",
    "During training, the model will observe rotated patterns and will learn to ignore the noise coming from the padding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, let's train the model now.\n",
    "The model is exactly the same used to train a normal *PyTorch* architecture:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prep the training dataset\n",
    "train_transform = Compose([\n",
    "    #pad,\n",
    "    #resize1,\n",
    "    #RandomRotation(180, resample=Image.BILINEAR, expand=False),\n",
    "    #resize2,\n",
    "    #ToTensor()\n",
    "])\n",
    "\n",
    "#data_train = DOTARotDataset(mode='train', transform=train_transform)\n",
    "#train_loader = torch.utils.data.DataLoader(data_train, batch_size=8, shuffle=True)\n",
    "#print(len(data_train), len(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fresh_training_data(n):\n",
    "    data_train = DOTARotDataset(mode='train', transform=train_transform, max_num_examples=n)\n",
    "    train_loader = torch.utils.data.DataLoader(data_train, batch_size=8, shuffle=True, drop_last=True)\n",
    "    #print(len(data_train), len(train_loader))\n",
    "    return train_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.num_samples 28838\n",
      "28838 3604\n"
     ]
    }
   ],
   "source": [
    "# Prep the testing dataset\n",
    "test_transform = Compose([\n",
    "    #pad,\n",
    "    #ToTensor()\n",
    "])\n",
    "\n",
    "data_test = DOTARotDataset(mode='test', transform=test_transform)\n",
    "test_loader = torch.utils.data.DataLoader(data_test, batch_size=8, shuffle=False, drop_last=True)\n",
    "print(len(data_test), len(test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mini = 99999\n",
    "# maxi = 0\n",
    "# for m in data_train: # data_test\n",
    "#     if m[1] < mini:\n",
    "#         mini = m[1]\n",
    "#     if m[1] > maxi:\n",
    "#         maxi = m[1]\n",
    "# print(mini, maxi, \"<--- should be 0 14 instead of 1 15\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model\n",
    "loss_function = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=5e-5, weight_decay=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_the_model(model, cyclic_group, epoch, train_acc, train_loss, test_acc, test_loss):\n",
    "    if not os.path.exists(\"models\"):\n",
    "        os.mkdir(\"models\")\n",
    "    model_name = \"models/model_dota_C\"+str(cyclic_group)+\"_\"+str(epoch)+\"_\"+str(round(train_acc,4))+\"_\"+str(round(train_loss,4))+\"_\"+str(round(test_acc,4))+\"_\"+str(round(test_loss,4))+\".pth\"\n",
    "#    if not os.path.exists(\"models/model_dota.pth\"):\n",
    "    torch.save(model.state_dict(), model_name)\n",
    "#    print('saved')\n",
    "#    else:\n",
    "#         model.load_state_dict(torch.load(\"models/model_dota.pth\"))\n",
    "#         print('loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_the_results(cyclic_group, epoch, train_accuracy, train_loss, test_accuracy, test_loss):\n",
    "    add_headers = False\n",
    "    if not os.path.exists(\"results\"):\n",
    "        os.mkdir(\"results\")\n",
    "    if not os.path.exists(\"results/model_dota.csv\"):\n",
    "        add_headers = True\n",
    "    # writing to csv file\n",
    "    with open(\"results/model_dota.csv\", 'a', newline='') as csvfile: \n",
    "        # creating a csv writer object \n",
    "        csvwriter = csv.writer(csvfile)\n",
    "\n",
    "        if add_headers:\n",
    "            csvwriter.writerow(['Cyclic Group', 'Epoch', 'Train Accuracy', 'Train Loss', 'Test Accuracy', 'Test Loss'])\n",
    "\n",
    "        # writing the data rows\n",
    "        csvwriter.writerow([cyclic_group, epoch, train_accuracy, train_loss, test_accuracy, test_loss])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # get initial performance with random weights\n",
    "# test_total = 0\n",
    "# test_correct = 0\n",
    "# test_loss = 0\n",
    "# with torch.no_grad():\n",
    "#     model.eval()\n",
    "    \n",
    "#     #for i, (x, t) in enumerate(test_loader):\n",
    "#     with tqdm(test_loader, unit=\"batch\") as tepoch:\n",
    "#         for x, t in tepoch:\n",
    "#             tepoch.set_description(f\"Epoch {-1}\")\n",
    "            \n",
    "#             #if i%1000==0:\n",
    "#             #    print(i, \"/\", len(test_loader))\n",
    "\n",
    "#             x = x.to(device)\n",
    "#             t = t.to(device)\n",
    "\n",
    "#             y = model(x)\n",
    "\n",
    "#             _, prediction = torch.max(y.data, 1)\n",
    "#             if prediction.shape[0] != t.shape[0]:\n",
    "#                 print(t)\n",
    "#                 t = t[:-(t.shape[0]-prediction.shape[0])]\n",
    "#                 print(t)\n",
    "#             test_total += t.shape[0]\n",
    "#             test_correct += (prediction == t).sum().item()\n",
    "\n",
    "#             loss = loss_function(y, t)\n",
    "#             test_loss += loss\n",
    "\n",
    "# test_accuracy = test_correct/test_total*100.\n",
    "    \n",
    "# print(f\"test accuracy: {test_accuracy}\")\n",
    "# print(f\"test loss: {test_loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_the_results(cyclic_group, 0, 0, test_accuracy, test_loss.item())\n",
    "# save_the_model(model, cyclic_group, 0, 0, 0, test_accuracy, test_loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################\n",
    "# IF CONTINUING TRAINING, LOAD MODEL FROM LAST EPOCH\n",
    "######################################################\n",
    "\n",
    "# train_loader = get_fresh_training_data(30000)\n",
    "# model.load_state_dict(torch.load(\"models/model_dota_59_97.0042_1035.413_83.879_2458.3879.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting epoch 0\n",
      "self.num_samples 6961\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|| 870/870 [05:05<00:00,  2.84batch/s] \n",
      "Epoch 0: 100%|| 3604/3604 [05:11<00:00, 11.58batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting epoch 1\n",
      "self.num_samples 7975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|| 996/996 [04:32<00:00,  3.66batch/s]\n",
      "Epoch 1: 100%|| 3604/3604 [05:06<00:00, 11.77batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting epoch 2\n",
      "self.num_samples 8904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|| 1113/1113 [05:04<00:00,  3.65batch/s]\n",
      "Epoch 2: 100%|| 3604/3604 [05:07<00:00, 11.73batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting epoch 3\n",
      "self.num_samples 9804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|| 1225/1225 [05:43<00:00,  3.56batch/s]\n",
      "Epoch 3: 100%|| 3604/3604 [05:07<00:00, 11.71batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting epoch 4\n",
      "self.num_samples 10704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|| 1338/1338 [06:05<00:00,  3.66batch/s]\n",
      "Epoch 4: 100%|| 3604/3604 [05:07<00:00, 11.72batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting epoch 5\n",
      "self.num_samples 11604\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|| 1450/1450 [06:36<00:00,  3.66batch/s]\n",
      "Epoch 5: 100%|| 3604/3604 [05:06<00:00, 11.77batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting epoch 6\n",
      "self.num_samples 12504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|| 1563/1563 [07:07<00:00,  3.66batch/s]\n",
      "Epoch 6: 100%|| 3604/3604 [05:06<00:00, 11.75batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting epoch 7\n",
      "self.num_samples 13404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|| 1675/1675 [07:37<00:00,  3.66batch/s]\n",
      "Epoch 7: 100%|| 3604/3604 [05:07<00:00, 11.74batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting epoch 8\n",
      "self.num_samples 14304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|| 1788/1788 [08:09<00:00,  3.65batch/s]\n",
      "Epoch 8: 100%|| 3604/3604 [05:09<00:00, 11.66batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting epoch 9\n",
      "self.num_samples 15204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|| 1900/1900 [08:55<00:00,  3.55batch/s]\n",
      "Epoch 9: 100%|| 3604/3604 [05:12<00:00, 11.54batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting epoch 10\n",
      "self.num_samples 16104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|| 2013/2013 [09:28<00:00,  3.54batch/s]\n",
      "Epoch 10: 100%|| 3604/3604 [05:14<00:00, 11.46batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting epoch 11\n",
      "self.num_samples 17004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11: 100%|| 2125/2125 [09:59<00:00,  3.54batch/s]\n",
      "Epoch 11: 100%|| 3604/3604 [05:14<00:00, 11.46batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting epoch 12\n",
      "self.num_samples 17904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12: 100%|| 2238/2238 [10:31<00:00,  3.54batch/s]\n",
      "Epoch 12: 100%|| 3604/3604 [05:15<00:00, 11.41batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting epoch 13\n",
      "self.num_samples 18739\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13: 100%|| 2342/2342 [11:01<00:00,  3.54batch/s]\n",
      "Epoch 13: 100%|| 3604/3604 [05:18<00:00, 11.33batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting epoch 14\n",
      "self.num_samples 19539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|| 2442/2442 [11:29<00:00,  3.54batch/s]\n",
      "Epoch 14: 100%|| 3604/3604 [05:13<00:00, 11.49batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting epoch 15\n",
      "self.num_samples 20339\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15: 100%|| 2542/2542 [11:42<00:00,  3.62batch/s]\n",
      "Epoch 15: 100%|| 3604/3604 [05:16<00:00, 11.40batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting epoch 16\n",
      "self.num_samples 21085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16: 100%|| 2635/2635 [12:08<00:00,  3.62batch/s]\n",
      "Epoch 16: 100%|| 3604/3604 [05:15<00:00, 11.42batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting epoch 17\n",
      "self.num_samples 21785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17: 100%|| 2723/2723 [12:32<00:00,  3.62batch/s]\n",
      "Epoch 17: 100%|| 3604/3604 [05:16<00:00, 11.40batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting epoch 18\n",
      "self.num_samples 22485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18: 100%|| 2810/2810 [12:57<00:00,  3.62batch/s]\n",
      "Epoch 18: 100%|| 3604/3604 [05:17<00:00, 11.36batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting epoch 19\n",
      "self.num_samples 23151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|| 2893/2893 [13:27<00:00,  3.58batch/s]\n",
      "Epoch 19: 100%|| 3604/3604 [05:21<00:00, 11.21batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting epoch 20\n",
      "self.num_samples 23751\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20: 100%|| 2968/2968 [13:58<00:00,  3.54batch/s]\n",
      "Epoch 20: 100%|| 3604/3604 [05:21<00:00, 11.20batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting epoch 21\n",
      "self.num_samples 24351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21: 100%|| 3043/3043 [14:20<00:00,  3.54batch/s]\n",
      "Epoch 21: 100%|| 3604/3604 [05:22<00:00, 11.17batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting epoch 22\n",
      "self.num_samples 24951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22: 100%|| 3118/3118 [14:40<00:00,  3.54batch/s]\n",
      "Epoch 22: 100%|| 3604/3604 [05:23<00:00, 11.15batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting epoch 23\n",
      "self.num_samples 25551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23: 100%|| 3193/3193 [15:04<00:00,  3.53batch/s]\n",
      "Epoch 23: 100%|| 3604/3604 [05:24<00:00, 11.11batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting epoch 24\n",
      "self.num_samples 26151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|| 3268/3268 [15:26<00:00,  3.53batch/s]\n",
      "Epoch 24: 100%|| 3604/3604 [05:27<00:00, 11.02batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting epoch 25\n",
      "self.num_samples 26751\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25: 100%|| 3343/3343 [15:48<00:00,  3.52batch/s]\n",
      "Epoch 25: 100%|| 3604/3604 [05:26<00:00, 11.03batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting epoch 26\n",
      "self.num_samples 27351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26: 100%|| 3418/3418 [16:10<00:00,  3.52batch/s]\n",
      "Epoch 26: 100%|| 3604/3604 [05:28<00:00, 10.97batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting epoch 27\n",
      "self.num_samples 27951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27: 100%|| 3493/3493 [16:30<00:00,  3.53batch/s]\n",
      "Epoch 27: 100%|| 3604/3604 [05:27<00:00, 10.99batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting epoch 28\n",
      "self.num_samples 28551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28: 100%|| 3568/3568 [16:50<00:00,  3.53batch/s]\n",
      "Epoch 28: 100%|| 3604/3604 [05:28<00:00, 10.96batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting epoch 29\n",
      "self.num_samples 29151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29: 100%|| 3643/3643 [17:11<00:00,  3.53batch/s]\n",
      "Epoch 29: 100%|| 3604/3604 [05:29<00:00, 10.95batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting epoch 30\n",
      "self.num_samples 29751\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30: 100%|| 3718/3718 [17:31<00:00,  3.54batch/s]\n",
      "Epoch 30: 100%|| 3604/3604 [05:28<00:00, 10.96batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting epoch 31\n",
      "self.num_samples 30351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31: 100%|| 3793/3793 [17:51<00:00,  3.54batch/s]\n",
      "Epoch 31: 100%|| 3604/3604 [05:29<00:00, 10.95batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting epoch 32\n",
      "self.num_samples 30951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32: 100%|| 3868/3868 [18:13<00:00,  3.54batch/s]\n",
      "Epoch 32: 100%|| 3604/3604 [05:29<00:00, 10.95batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting epoch 33\n",
      "self.num_samples 31551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33: 100%|| 3943/3943 [18:34<00:00,  3.54batch/s]\n",
      "Epoch 33: 100%|| 3604/3604 [05:29<00:00, 10.94batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting epoch 34\n",
      "self.num_samples 32151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34: 100%|| 4018/4018 [18:54<00:00,  3.54batch/s]\n",
      "Epoch 34: 100%|| 3604/3604 [05:29<00:00, 10.94batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting epoch 35\n",
      "self.num_samples 32751\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35: 100%|| 4093/4093 [19:14<00:00,  3.54batch/s]\n",
      "Epoch 35: 100%|| 3604/3604 [05:22<00:00, 11.19batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting epoch 36\n",
      "self.num_samples 33351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36: 100%|| 4168/4168 [19:36<00:00,  3.54batch/s]\n",
      "Epoch 36: 100%|| 3604/3604 [05:30<00:00, 10.89batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting epoch 37\n",
      "self.num_samples 33951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37: 100%|| 4243/4243 [19:56<00:00,  3.55batch/s]\n",
      "Epoch 37: 100%|| 3604/3604 [05:30<00:00, 10.90batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting epoch 38\n",
      "self.num_samples 34551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 38: 100%|| 4318/4318 [20:18<00:00,  3.55batch/s]\n",
      "Epoch 38: 100%|| 3604/3604 [05:30<00:00, 10.89batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting epoch 39\n",
      "self.num_samples 35151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39: 100%|| 4393/4393 [20:38<00:00,  3.55batch/s]\n",
      "Epoch 39: 100%|| 3604/3604 [05:31<00:00, 10.88batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting epoch 40\n",
      "self.num_samples 35751\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 40: 100%|| 4468/4468 [21:00<00:00,  3.54batch/s]\n",
      "Epoch 40: 100%|| 3604/3604 [05:33<00:00, 10.81batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting epoch 41\n",
      "self.num_samples 36351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 41: 100%|| 4543/4543 [21:21<00:00,  3.54batch/s]\n",
      "Epoch 41: 100%|| 3604/3604 [05:32<00:00, 10.83batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting epoch 42\n",
      "self.num_samples 36951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 42: 100%|| 4618/4618 [21:43<00:00,  3.54batch/s]\n",
      "Epoch 42: 100%|| 3604/3604 [05:33<00:00, 10.80batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting epoch 43\n",
      "self.num_samples 37551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 43: 100%|| 4693/4693 [22:04<00:00,  3.54batch/s]\n",
      "Epoch 43: 100%|| 3604/3604 [05:34<00:00, 10.78batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting epoch 44\n",
      "self.num_samples 38151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 44: 100%|| 4768/4768 [22:25<00:00,  3.54batch/s]\n",
      "Epoch 44: 100%|| 3604/3604 [05:34<00:00, 10.79batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting epoch 45\n",
      "self.num_samples 38751\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 45: 100%|| 4843/4843 [22:18<00:00,  3.62batch/s] \n",
      "Epoch 45: 100%|| 3604/3604 [05:33<00:00, 10.80batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting epoch 46\n",
      "self.num_samples 39279\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 46: 100%|| 4909/4909 [22:42<00:00,  3.60batch/s]\n",
      "Epoch 46: 100%|| 3604/3604 [05:24<00:00, 11.11batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting epoch 47\n",
      "self.num_samples 39779\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 47: 100%|| 4972/4972 [22:59<00:00,  3.60batch/s]\n",
      "Epoch 47: 100%|| 3604/3604 [07:18<00:00,  8.23batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting epoch 48\n",
      "self.num_samples 40279\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 48: 100%|| 5034/5034 [42:38<00:00,  1.97batch/s]  \n",
      "Epoch 48: 100%|| 3604/3604 [05:37<00:00, 10.69batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting epoch 49\n",
      "self.num_samples 40779\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|| 5097/5097 [23:54<00:00,  3.55batch/s]\n",
      "Epoch 49: 100%|| 3604/3604 [05:30<00:00, 10.89batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting epoch 50\n",
      "self.num_samples 41279\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 50: 100%|| 5159/5159 [23:48<00:00,  3.61batch/s]\n",
      "Epoch 50: 100%|| 3604/3604 [05:31<00:00, 10.89batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting epoch 51\n",
      "self.num_samples 41779\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 51: 100%|| 5222/5222 [24:34<00:00,  3.54batch/s]\n",
      "Epoch 51: 100%|| 3604/3604 [05:40<00:00, 10.57batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting epoch 52\n",
      "self.num_samples 42279\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 52: 100%|| 5284/5284 [24:46<00:00,  3.55batch/s]\n",
      "Epoch 52: 100%|| 3604/3604 [05:37<00:00, 10.67batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting epoch 53\n",
      "self.num_samples 42779\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 53: 100%|| 5347/5347 [28:40<00:00,  3.11batch/s]\n",
      "Epoch 53: 100%|| 3604/3604 [05:41<00:00, 10.56batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting epoch 54\n",
      "self.num_samples 43279\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 54: 100%|| 5409/5409 [25:20<00:00,  3.56batch/s]\n",
      "Epoch 54: 100%|| 3604/3604 [05:38<00:00, 10.66batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting epoch 55\n",
      "self.num_samples 43761\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 55: 100%|| 5470/5470 [25:37<00:00,  3.56batch/s]\n",
      "Epoch 55: 100%|| 3604/3604 [05:40<00:00, 10.59batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting epoch 56\n",
      "self.num_samples 44161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 56: 100%|| 5520/5520 [25:59<00:00,  3.54batch/s]\n",
      "Epoch 56: 100%|| 3604/3604 [05:42<00:00, 10.52batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting epoch 57\n",
      "self.num_samples 44561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 57: 100%|| 5570/5570 [26:06<00:00,  3.56batch/s]\n",
      "Epoch 57: 100%|| 3604/3604 [05:40<00:00, 10.58batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting epoch 58\n",
      "self.num_samples 44961\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 58: 100%|| 5620/5620 [26:21<00:00,  3.55batch/s]\n",
      "Epoch 58: 100%|| 3604/3604 [05:42<00:00, 10.53batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting epoch 59\n",
      "self.num_samples 45361\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 59: 100%|| 5670/5670 [26:35<00:00,  3.55batch/s]\n",
      "Epoch 59: 100%|| 3604/3604 [05:43<00:00, 10.50batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting epoch 60\n",
      "self.num_samples 45761\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 60: 100%|| 5720/5720 [26:48<00:00,  3.56batch/s]\n",
      "Epoch 60: 100%|| 3604/3604 [05:44<00:00, 10.48batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting epoch 61\n",
      "self.num_samples 46161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 61: 100%|| 5770/5770 [27:02<00:00,  3.56batch/s]\n",
      "Epoch 61: 100%|| 3604/3604 [05:43<00:00, 10.48batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting epoch 62\n",
      "self.num_samples 46561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 62: 100%|| 5820/5820 [27:15<00:00,  3.56batch/s]\n",
      "Epoch 62: 100%|| 3604/3604 [05:43<00:00, 10.49batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting epoch 63\n",
      "self.num_samples 46961\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 63: 100%|| 5870/5870 [27:28<00:00,  3.56batch/s]\n",
      "Epoch 63: 100%|| 3604/3604 [05:43<00:00, 10.50batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting epoch 64\n",
      "self.num_samples 47361\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 64: 100%|| 5920/5920 [27:42<00:00,  3.56batch/s]\n",
      "Epoch 64: 100%|| 3604/3604 [05:46<00:00, 10.39batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting epoch 65\n",
      "self.num_samples 47761\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 65:   9%|         | 543/5970 [02:32<25:20,  3.57batch/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_9336/4195781392.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     31\u001b[0m             \u001b[0mt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m             \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m             \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprediction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\pytorch38\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_9336/33896975.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    133\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    134\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mblock3\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 135\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mblock4\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    136\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpool2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    137\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\pytorch38\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\school\\e2cnn_experiments\\e2cnn\\nn\\modules\\sequential_module.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     78\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 80\u001b[1;33m             \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     81\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mout_type\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\pytorch38\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\school\\e2cnn_experiments\\e2cnn\\nn\\modules\\batchnormalization\\inner.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    138\u001b[0m                 \u001b[1;31m# if the fields were contiguous, we can use slicing\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    139\u001b[0m                 output[:, indices[0]:indices[1], :, :] = batchnorm(\n\u001b[1;32m--> 140\u001b[1;33m                     \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    141\u001b[0m                 ).view(b, -1, h, w)\n\u001b[0;32m    142\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "samples_per_class = 500\n",
    "start_epoch = 0\n",
    "max_epochs = 100\n",
    "\n",
    "for epoch in range(start_epoch, max_epochs):\n",
    "    \n",
    "    print('starting epoch', epoch)\n",
    "    \n",
    "    ########################################\n",
    "    # TRAIN\n",
    "    ########################################\n",
    "    train_total = 0\n",
    "    train_correct = 0\n",
    "    train_loss = 0\n",
    "    model.train()\n",
    "    \n",
    "    train_loader = get_fresh_training_data(samples_per_class)\n",
    "    print(\"samples_per_class\", samples_per_class)\n",
    "    samples_per_class += 100\n",
    "    \n",
    "    #for i, (x, t) in enumerate(train_loader):\n",
    "    with tqdm(train_loader, unit=\"batch\") as tepoch:\n",
    "        for x, t in tepoch:\n",
    "            tepoch.set_description(f\"Epoch {epoch}\")\n",
    "\n",
    "            #if i%5000==0:\n",
    "            #    print(i, \"/\", len(train_loader))\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            x = x.to(device)\n",
    "            t = t.to(device)\n",
    "\n",
    "            y = model(x)\n",
    "\n",
    "            _, prediction = torch.max(y.data, 1)\n",
    "            # sometimes at the end of an epoch, prediction.shape can be < t.shape\n",
    "            if prediction.shape[0] != t.shape[0]:\n",
    "                #print(t)\n",
    "                t = t[:-(t.shape[0]-prediction.shape[0])]\n",
    "                #print(t)\n",
    "            train_total += t.shape[0]\n",
    "            train_correct += (prediction == t).sum().item()\n",
    "\n",
    "            loss = loss_function(y, t)\n",
    "            train_loss += loss\n",
    "\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "    tepoch.close()\n",
    "\n",
    "    ########################################\n",
    "    # TEST\n",
    "    ########################################\n",
    "    test_total = 0\n",
    "    test_correct = 0\n",
    "    test_loss = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        \n",
    "        #for i, (x, t) in enumerate(test_loader):\n",
    "        with tqdm(test_loader, unit=\"batch\") as tepoch:\n",
    "            for x, t in tepoch:\n",
    "                tepoch.set_description(f\"Epoch {epoch}\")\n",
    "                \n",
    "                #if i%5000==0:\n",
    "                #    print(i, \"/\", len(test_loader))\n",
    "\n",
    "                x = x.to(device)\n",
    "                t = t.to(device)\n",
    "\n",
    "                y = model(x)\n",
    "\n",
    "                _, prediction = torch.max(y.data, 1)\n",
    "                if prediction.shape[0] != t.shape[0]:\n",
    "                    #print(t)\n",
    "                    t = t[:-(t.shape[0]-prediction.shape[0])]\n",
    "                    #print(t)\n",
    "                test_total += t.shape[0]\n",
    "                test_correct += (prediction == t).sum().item()\n",
    "\n",
    "                loss = loss_function(y, t)\n",
    "                test_loss += loss\n",
    "\n",
    "    train_accuracy = train_correct/train_total*100.\n",
    "    test_accuracy = test_correct/test_total*100.\n",
    "\n",
    "    #print(f\"epoch {epoch} | train accuracy: {train_accuracy}\")\n",
    "    #print(f\"epoch {epoch} | train loss: {train_loss.item()}\")\n",
    "    #print(f\"epoch {epoch} | test accuracy: {test_accuracy}\")\n",
    "    #print(f\"epoch {epoch} | test loss: {test_loss.item()}\")\n",
    "\n",
    "    tepoch.set_postfix({\"train_accuracy\":train_accuracy, \n",
    "                        \"train_loss\":train_loss.item(),\n",
    "                        \"test_accuracy\":test_accuracy,\n",
    "                        \"test_loss\":test_loss.item()})\n",
    "    tepoch.close()\n",
    "    time.sleep(0.5)\n",
    "    \n",
    "    save_the_results(cyclic_group, epoch, train_accuracy, train_loss.item(), test_accuracy, test_loss.item())\n",
    "    save_the_model(model, cyclic_group, epoch, train_accuracy, train_loss.item(), test_accuracy, test_loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_accuracy = train_correct/train_total*100.\n",
    "# print(train_correct, train_total, train_accuracy)\n",
    "#save_the_results(cyclic_group, epoch, train_accuracy, train_loss.item(), test_accuracy, test_loss.item())\n",
    "#save_the_model(model, cyclic_group, epoch, train_accuracy, train_loss.item(), test_accuracy, test_loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(prediction.shape, t.shape)\n",
    "# print(prediction)\n",
    "# print(t)\n",
    "# print(t[:-1])\n",
    "# print(y.shape)\n",
    "# print(torch.max(y.data, 1)) # 1 is the dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# epoch -1 | test accuracy: 10.011096469935502\n",
    "# epoch -1 | test loss: 2109988.5\n",
    "\n",
    "# epoch 0 | train accuracy: 52.91684784257414\n",
    "# epoch 0 | train loss: 42925.43359375\n",
    "# epoch 0 | test accuracy: 18.846660656078782\n",
    "# epoch 0 | test loss: 201328.765625"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_test = DOTARotDataset(mode='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "##########################################################################################\n",
      "angle |       0       1       2       3       4       5       6       7       8       9      10      11      12      13      14\n",
      "  0:[ -0.9596  -4.8888   5.9464  -3.2338  -2.3149 -11.3817  -2.4831 -11.5027  -1.2079   0.5564   0.737   -5.1735  -1.4842 -11.1275  -0.8537]\n",
      " 45:[ -0.9515  -4.8922   5.9272  -3.2435  -2.309  -11.3752  -2.4823 -11.5275  -1.2121   0.574    0.7156  -5.1749  -1.484  -11.1018  -0.8391]\n",
      " 90:[ -0.9535  -4.8953   5.9379  -3.2481  -2.3075 -11.3579  -2.4622 -11.5154  -1.2262   0.5651   0.72    -5.1597  -1.479  -11.0946  -0.8476]\n",
      "135:[ -0.9528  -4.9033   5.9461  -3.2624  -2.2945 -11.3566  -2.4489 -11.4927  -1.2168   0.5497   0.6955  -5.1521  -1.4605 -11.0987  -0.8426]\n",
      "180:[ -0.9504  -4.895    5.9334  -3.2491  -2.2891 -11.3684  -2.4532 -11.491   -1.2094   0.5527   0.7088  -5.1644  -1.4622 -11.1106  -0.8529]\n",
      "225:[ -0.9533  -4.8964   5.9366  -3.2424  -2.2844 -11.3635  -2.4812 -11.4819  -1.2194   0.56     0.7102  -5.1679  -1.4581 -11.1286  -0.8495]\n",
      "270:[ -0.9509  -4.8733   5.9359  -3.248   -2.2853 -11.3713  -2.4895 -11.4909  -1.1927   0.5589   0.7098  -5.1807  -1.4703 -11.1363  -0.836 ]\n",
      "315:[ -0.9663  -4.8748   5.9311  -3.2427  -2.2898 -11.3763  -2.4966 -11.493   -1.1978   0.5612   0.7218  -5.1779  -1.478  -11.1325  -0.8511]\n",
      "##########################################################################################\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# retrieve the first image from the test set\n",
    "x, y = next(iter(data_test))\n",
    "\n",
    "# evaluate the model\n",
    "test_model(model, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
